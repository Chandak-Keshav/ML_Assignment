{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmission_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88346340</td>\n",
       "      <td>2488608</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92001408</td>\n",
       "      <td>52133202</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>[100-125)</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169424316</td>\n",
       "      <td>40945509</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272987082</td>\n",
       "      <td>38850777</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150600612</td>\n",
       "      <td>72738225</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Down</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      enc_id  patient_id       race  gender      age     weight  \\\n",
       "0   88346340     2488608  Caucasian    Male  [60-70)        NaN   \n",
       "1   92001408    52133202  Caucasian    Male  [70-80)  [100-125)   \n",
       "2  169424316    40945509  Caucasian  Female  [70-80)        NaN   \n",
       "3  272987082    38850777  Caucasian  Female  [50-60)        NaN   \n",
       "4  150600612    72738225  Caucasian  Female  [80-90)        NaN   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  1                         2                    6   \n",
       "1                  2                         6                    1   \n",
       "2                  3                         2                    1   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         6                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 3  ...          No  Steady                   No   \n",
       "1                 7  ...          No      No                   No   \n",
       "2                 7  ...          No      Up                   No   \n",
       "3                 1  ...          No      No                   No   \n",
       "4                 6  ...          No    Down                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmission_id  \n",
       "0                      No      Ch         Yes              2  \n",
       "1                      No      No         Yes              1  \n",
       "2                      No      Ch         Yes              1  \n",
       "3                      No      No         Yes              2  \n",
       "4                      No      Ch         Yes              2  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = [col for col in df.columns \n",
    "                   if df[col].dtype == 'object' \n",
    "                   or df[col].dtype == 'bool' or df[col].dtype == 'category']\n",
    "numerical_col = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]\n",
    "dropped_cols = set(df.columns) - set(categorical_col) - set(numerical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns), len(categorical_col) + len(numerical_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'gender', 'age', 'weight', 'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed']\n",
      "['enc_id', 'patient_id', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'readmission_id']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_col)\n",
    "print(numerical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveNullCounts(df, columns):\n",
    "    for col in columns:\n",
    "        if col not in dropped_cols:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                print(col, df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "giveNullCounts(df, numerical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race 1621\n",
      "weight 68986\n",
      "payer_code 28178\n",
      "medical_specialty 34930\n",
      "diag_1 15\n",
      "diag_2 244\n",
      "diag_3 989\n",
      "max_glu_serum 67515\n",
      "A1Cresult 59356\n"
     ]
    }
   ],
   "source": [
    "giveNullCounts(df, categorical_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill race null values with 'Other'\n",
    "df['race'] = df['race'].replace(np.nan, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['weight', 'payer_code', 'medical_specialty'], inplace=True, axis=1)\n",
    "# add these columns to dropped_cols\n",
    "dropped_cols.update(['weight', 'payer_code', 'medical_specialty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag_1 15\n",
      "diag_2 244\n",
      "diag_3 989\n",
      "max_glu_serum 67515\n",
      "A1Cresult 59356\n"
     ]
    }
   ],
   "source": [
    "giveNullCounts(df, categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['diag_1', 'diag_2', 'diag_3'], inplace=True, axis=1)\n",
    "# add these columns to dropped_cols\n",
    "dropped_cols.update(['diag_1', 'diag_2', 'diag_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_glu_serum'] = df['max_glu_serum'].replace(np.nan, 'None')\n",
    "df['A1Cresult'] = df['A1Cresult'].replace(np.nan, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "giveNullCounts(df, categorical_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding / One-Hot Encoding / Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = ['metformin', 'repaglinide','glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone','insulin','citoglipton','nateglinide','chlorpropamide','acarbose','miglitol','glyburide-metformin', 'tolazamide','metformin-pioglitazone', 'metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin','troglitazone', 'tolbutamide', 'acetohexamide','examide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"number_of_no\"] = 0\n",
    "df[\"number_of_steady\"] = 0\n",
    "df[\"number_of_up\"] = 0\n",
    "df[\"number_of_down\"] = 0\n",
    "\n",
    "for drug in drugs:\n",
    "    df[\"number_of_no\"] += (df[drug] == 'No').astype(int)\n",
    "    df[\"number_of_steady\"] += (df[drug] == 'Steady').astype(int)\n",
    "    df[\"number_of_up\"] += (df[drug] == 'Up').astype(int)\n",
    "    df[\"number_of_down\"] += (df[drug] == 'Down').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drugs, inplace=True, axis=1)\n",
    "# add these columns to dropped_cols\n",
    "dropped_cols.update(drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race\n",
      "change\n",
      "A1Cresult\n",
      "diabetesMed\n",
      "max_glu_serum\n",
      "age\n",
      "gender\n"
     ]
    }
   ],
   "source": [
    "# new_cat_cols = categorical_col - dropped_cols\n",
    "new_cat_cols = list(set(categorical_col) - dropped_cols)\n",
    "for col in new_cat_cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop gender rows with value Unknown/Invalid\n",
    "df = df[df['gender'] != 'Unknown/Invalid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rlsha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# use one-hot encoding from pandas for new_cat_cols\n",
    "# also drop_first = True to avoid dummy trap\n",
    "# df = pd.get_dummies(df, columns=new_cat_cols, drop_first=True)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # Use drop='first' to handle multicollinearity\n",
    "\n",
    "data_to_encode = df[new_cat_cols]\n",
    "encoded_data = encoder.fit_transform(data_to_encode)\n",
    "encoded_column_names = encoder.get_feature_names_out(input_features=new_cat_cols)\n",
    "\n",
    "df = df.drop(columns=new_cat_cols)  # Drop the original columns\n",
    "df[encoded_column_names] = encoded_data  # Add the one-hot encoded columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering For Patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_test_df = pd.read_csv('./data/test.csv')\n",
    "lst = pd.concat([df['patient_id'], tmp_test_df['patient_id']]).tolist()\n",
    "pat = {}\n",
    "for i in lst:\n",
    "    if i in pat:\n",
    "        pat[i] += 1\n",
    "    else:\n",
    "        pat[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on = [i for i in pat if pat[i] == 1]\n",
    "# tw = [i for i in pat if pat[i] == 2]\n",
    "# mrth = [i for i in pat if pat[i] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bin(id):\n",
    "    return pat[id]\n",
    "    # if id in on:\n",
    "    #     return 1\n",
    "    # elif id in tw:\n",
    "    #     return 2\n",
    "    # elif id in mrth:\n",
    "    #     return 3\n",
    "    # else:\n",
    "    #     return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_patient_id\n",
       "1     38422\n",
       "2     14541\n",
       "3      6965\n",
       "4      3966\n",
       "5      2503\n",
       "6      1471\n",
       "7       993\n",
       "8       620\n",
       "9       446\n",
       "10      308\n",
       "12      161\n",
       "11      141\n",
       "13      126\n",
       "15       94\n",
       "20       86\n",
       "18       78\n",
       "23       58\n",
       "14       48\n",
       "19       41\n",
       "16       41\n",
       "22       33\n",
       "17       31\n",
       "40       26\n",
       "28       21\n",
       "21       13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_patient_id'] = df['patient_id'].apply(lambda x: calc_bin(x)).astype(int)\n",
    "df['new_patient_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_corr_features(corr_matrix: pd.DataFrame, threshold = 0.9):\n",
    "    corr_features = set()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                corr_features.add(corr_matrix.columns[i])\n",
    "\n",
    "    return corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_steady'}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_corr_features(df.corr(), threshold=0.85)\n",
    "# ! so we don't have any highly correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot(kind='box', subplots=True, layout=(5,4), sharex=False, sharey=False, figsize=(10,10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Things - Can Comment Out If Doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactionTerms = [\n",
    "#     ('num_medications','time_in_hospital'),\n",
    "#     ('num_medications','num_procedures'),\n",
    "#     ('time_in_hospital','num_lab_procedures'),\n",
    "#     ('num_medications','num_lab_procedures'),\n",
    "#     ('num_medications','number_diagnoses'),\n",
    "#     # ('age','number_diagnoses'), # ! age not present\n",
    "#     # ('change','num_medications'), # ! change not present\n",
    "#     ('number_diagnoses','time_in_hospital')\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inter in interactionTerms:\n",
    "#     name = inter[0] + '|' + inter[1]\n",
    "#     df[name] = df[inter[0]] * df[inter[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 71233 entries, 0 to 71235\n",
      "Data columns (total 41 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   enc_id                    71233 non-null  int64  \n",
      " 1   patient_id                71233 non-null  int64  \n",
      " 2   admission_type_id         71233 non-null  int64  \n",
      " 3   discharge_disposition_id  71233 non-null  int64  \n",
      " 4   admission_source_id       71233 non-null  int64  \n",
      " 5   time_in_hospital          71233 non-null  int64  \n",
      " 6   num_lab_procedures        71233 non-null  int64  \n",
      " 7   num_procedures            71233 non-null  int64  \n",
      " 8   num_medications           71233 non-null  int64  \n",
      " 9   number_outpatient         71233 non-null  int64  \n",
      " 10  number_emergency          71233 non-null  int64  \n",
      " 11  number_inpatient          71233 non-null  int64  \n",
      " 12  number_diagnoses          71233 non-null  int64  \n",
      " 13  readmission_id            71233 non-null  int64  \n",
      " 14  number_of_no              71233 non-null  int64  \n",
      " 15  number_of_steady          71233 non-null  int64  \n",
      " 16  number_of_up              71233 non-null  int64  \n",
      " 17  number_of_down            71233 non-null  int64  \n",
      " 18  race_Asian                71233 non-null  float64\n",
      " 19  race_Caucasian            71233 non-null  float64\n",
      " 20  race_Hispanic             71233 non-null  float64\n",
      " 21  race_Other                71233 non-null  float64\n",
      " 22  change_No                 71233 non-null  float64\n",
      " 23  A1Cresult_>8              71233 non-null  float64\n",
      " 24  A1Cresult_None            71233 non-null  float64\n",
      " 25  A1Cresult_Norm            71233 non-null  float64\n",
      " 26  diabetesMed_Yes           71233 non-null  float64\n",
      " 27  max_glu_serum_>300        71233 non-null  float64\n",
      " 28  max_glu_serum_None        71233 non-null  float64\n",
      " 29  max_glu_serum_Norm        71233 non-null  float64\n",
      " 30  age_[10-20)               71233 non-null  float64\n",
      " 31  age_[20-30)               71233 non-null  float64\n",
      " 32  age_[30-40)               71233 non-null  float64\n",
      " 33  age_[40-50)               71233 non-null  float64\n",
      " 34  age_[50-60)               71233 non-null  float64\n",
      " 35  age_[60-70)               71233 non-null  float64\n",
      " 36  age_[70-80)               71233 non-null  float64\n",
      " 37  age_[80-90)               71233 non-null  float64\n",
      " 38  age_[90-100)              71233 non-null  float64\n",
      " 39  gender_Male               71233 non-null  float64\n",
      " 40  new_patient_id            71233 non-null  int32  \n",
      "dtypes: float64(22), int32(1), int64(18)\n",
      "memory usage: 22.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('readmission_id', axis=1), \n",
    "    df['readmission_id'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56986, 40) (56986,)\n",
      "(14247, 40) (14247,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\n",
    "#     ('random_forest', RandomForestClassifier()),\n",
    "#     ('gradient_boosting', GradientBoostingClassifier()),\n",
    "#     ('xgboost', XGBClassifier()),\n",
    "#     ('catboost', CatBoostClassifier())\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pipeline\n",
    "Right now we don't need to do any preprocessing, but we will create a pipeline for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# def createPipeline(model_name, model) -> Pipeline:\n",
    "#     \"\"\"\n",
    "#     We can add more steps to the pipeline if you want\n",
    "#     \"\"\"\n",
    "#     return Pipeline([\n",
    "#         (model_name, model)\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection using K-Fold Cross Validation\n",
    "`N_SPLITS`: we will use 5-fold cross-validation. You can try different values for N_SPLITS and see how it affects the results.\n",
    "\n",
    "**K Fold Validation**: Use StratifiedKFold for classification problems and KFold for regression problems. `N_SPLITS` is the number of folds. shuffle is used to shuffle the data before splitting into batches. random_state is used to set the seed for random shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_SPLITS = 5 # ! number of KFold splits\n",
    "# stratified_k_fold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_accuracy = float('-inf')\n",
    "# best_model_pipeline = None\n",
    "# best_model_name = None\n",
    "\n",
    "# for model_name, model in models:\n",
    "#     print(\"-\"*40)\n",
    "#     print(f\"Training MODEL: {model_name}\")\n",
    "#     print(\"-\"*40)\n",
    "\n",
    "#     accuracy_scores = [] # ! will use this to find average accuracy score on validation set\n",
    "\n",
    "#     for fold, (train_index, val_index) in enumerate(stratified_k_fold.split(X_train, y_train)):\n",
    "#         print(f\"Fold: {fold+1}/{N_SPLITS}\")\n",
    "\n",
    "#         # ! get training and validation set using the fold indices\n",
    "#         X_train_fold = X_train.iloc[train_index]\n",
    "#         X_val_fold = X_train.iloc[val_index]\n",
    "#         y_train_fold = y_train.iloc[train_index]\n",
    "#         y_val_fold = y_train.iloc[val_index]\n",
    "\n",
    "\n",
    "#         # ! pipeline.fit(X, y) -> will first call steps in pipeline and then model.fit(X, y) for us\n",
    "#         pipeline = createPipeline(model_name, model)\n",
    "\n",
    "#         # ! fit the pipeline on training data\n",
    "#         pipeline.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "#         # ! get predictions on validation set\n",
    "#         y_pred_val = pipeline.predict(X_val_fold)\n",
    "\n",
    "#         # ! calculate validation accuracy score\n",
    "#         accuracy_val = accuracy_score(y_val_fold, y_pred_val)\n",
    "#         accuracy_scores.append(accuracy_val)\n",
    "\n",
    "#         print(f\"Validation Accuracy Score: {accuracy_val:.4f}\")\n",
    "#         print()\n",
    "\n",
    "#     average_accuracy_score = np.mean(accuracy_scores)\n",
    "#     print(f\"Average Validation Accuracy Score: {average_accuracy_score:.4f}\")\n",
    "\n",
    "#     # ! select best model based on average validation loss\n",
    "#     if average_accuracy_score > best_accuracy:\n",
    "#         best_accuracy = average_accuracy_score\n",
    "#         best_model_pipeline = pipeline\n",
    "#         best_model_name = model_name\n",
    "\n",
    "# print(\"-\"*40)\n",
    "# print(f\"Best Validation Accuracy Score: {best_accuracy:.4f}\")\n",
    "# print(f\"Best model: {best_model_name}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # ! we can add more parameters to the grid search\n",
    "# params = {\n",
    "#     \"max_depth\": [300, 500, 700, 800],\n",
    "#     \"max_leaf_nodes\": [1000, 1300, 1600]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(),\n",
    "#     param_grid=params,\n",
    "#     scoring=\"accuracy\",\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grad_boost = GradientBoostingClassifier()\n",
    "# grad_boost.fit(X_train, y_train)\n",
    "# model = grid_search.best_estimator_\n",
    "# model = RandomForestClassifier()\n",
    "# model = GradientBoostingClassifier()\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by Patient ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.72\n",
      "micro: 0.72\n",
      "macro: 0.66 \n",
      "weighted: 0.71 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.06      0.10      1581\n",
      "           1       0.63      0.69      0.66      5036\n",
      "           2       0.79      0.89      0.83      7630\n",
      "\n",
      "    accuracy                           0.72     14247\n",
      "   macro avg       0.66      0.54      0.53     14247\n",
      "weighted avg       0.71      0.72      0.69     14247\n",
      "\n",
      "[[  87 1168  326]\n",
      " [  58 3457 1521]\n",
      " [  13  832 6785]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"micro: {:.2f}\".format(metrics.precision_score(y_test, y_pred, average='micro')))\n",
    "print(\"macro: {:.2f} \".format( metrics.precision_score(y_test, y_pred, average='macro')))\n",
    "print(\"weighted: {:.2f} \".format( metrics.precision_score(y_test, y_pred, average='weighted'))) \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['race'] = test_df['race'].replace(np.nan, 'Other')\n",
    "test_df.drop(['weight', 'payer_code', 'medical_specialty'], inplace=True, axis=1)\n",
    "test_df.drop(['diag_1', 'diag_2', 'diag_3'], inplace=True, axis=1)\n",
    "test_df['max_glu_serum'] = test_df['max_glu_serum'].replace(np.nan, 'None')\n",
    "test_df['A1Cresult'] = test_df['A1Cresult'].replace(np.nan, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"number_of_no\"] = 0\n",
    "test_df[\"number_of_steady\"] = 0\n",
    "test_df[\"number_of_up\"] = 0\n",
    "test_df[\"number_of_down\"] = 0\n",
    "\n",
    "for drug in drugs:\n",
    "    test_df[\"number_of_no\"] += (test_df[drug] == 'No').astype(int)\n",
    "    test_df[\"number_of_steady\"] += (test_df[drug] == 'Steady').astype(int)\n",
    "    test_df[\"number_of_up\"] += (test_df[drug] == 'Up').astype(int)\n",
    "    test_df[\"number_of_down\"] += (test_df[drug] == 'Down').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(drugs, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop gender rows with value Unknown/Invalid\n",
    "test_df = test_df[test_df['gender'] != 'Unknown/Invalid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rlsha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # Use drop='first' to handle multicollinearity\n",
    "\n",
    "data_to_encode = test_df[new_cat_cols]\n",
    "encoded_data = encoder.fit_transform(data_to_encode)\n",
    "encoded_column_names = encoder.get_feature_names_out(input_features=new_cat_cols)\n",
    "\n",
    "test_df = test_df.drop(columns=new_cat_cols)  # Drop the original columns\n",
    "test_df[encoded_column_names] = encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for Patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = test_df['patient_id'].to_list()\n",
    "# pat = {}\n",
    "# for i in lst:\n",
    "#     if i in pat:\n",
    "#         pat[i] += 1\n",
    "#     else:\n",
    "#         pat[i] = 1\n",
    "# on = [i for i in pat if pat[i] == 1]\n",
    "# tw = [i for i in pat if pat[i] == 2]\n",
    "# mrth = [i for i in pat if pat[i] > 2]\n",
    "# def calc_bin(id):\n",
    "#     return pat[id]\n",
    "    # if id in on:\n",
    "    #     return 1\n",
    "    # elif id in tw:\n",
    "    #     return 2\n",
    "    # elif id in mrth:\n",
    "    #     return 3\n",
    "    # else:\n",
    "    #     return 0\n",
    "test_df['new_patient_id'] = test_df['patient_id'].apply(lambda x: calc_bin(x)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inter in interactionTerms:\n",
    "#     name = inter[0] + '|' + inter[1]\n",
    "#     test_df[name] = test_df[inter[0]] * test_df[inter[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(test_pred)\n",
    "result_df['readmission_id']=test_pred\n",
    "result_df['enc_id']=test_df['enc_id']\n",
    "cvfile = pd.concat((result_df[\"enc_id\"], result_df[\"readmission_id\"]), axis=1)\n",
    "cvfile.to_csv('finale.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
